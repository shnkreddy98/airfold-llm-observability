import random
import uuid

# Random user agents
user_agents = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64)",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)",
    "Mozilla/5.0 (X11; Linux x86_64)",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)"
]

llm_models = [
    'gpt-4o-realtime-preview-2024-12-17', 'gpt-4-1106-preview', 'gpt-4-turbo-preview', 'babbage-002',
    'gpt-4', 'chatgpt-4o-latest', 'o1-preview-2024-09-12', 'gpt-4o-mini-realtime-preview',
    'gpt-4o-mini-realtime-preview-2024-12-17', 'gpt-4.1-nano', 'gpt-3.5-turbo-instruct-0914',
    'gpt-4.1-nano-2025-04-14', 'gpt-3.5-turbo-16k', 'gpt-4o-realtime-preview', 'davinci-002',
    'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo', 'o3-mini-2025-01-31',
    'gpt-4-0125-preview', 'gpt-4o-2024-11-20', 'gpt-4o-2024-05-13', 'o1-2024-12-17',
    'o1', 'o1-preview', 'gpt-4-0613', 'o1-mini', 'gpt-4.5-preview', 'o1-pro',
    'gpt-4.5-preview-2025-02-27', 'gpt-4o-search-preview-2025-03-11', 'gpt-4-turbo-2024-04-09',
    'gpt-3.5-turbo-0125', 'gpt-4o', 'gpt-4o-2024-08-06', 'gpt-4o-mini-2024-07-18',
    'gpt-4.1-mini', 'gpt-4o-mini', 'gpt-4.1-mini-2025-04-14', 'o3-mini', 'gpt-4.1', 
    'gpt-4.1-2025-04-14', 'o4-mini-2025-04-16', 'o4-mini','codex-mini-latest'
]

def random_probabilities(n):
    probabilities = [random.random() for _ in range(n)]
    total = sum(probabilities)
    return [p / total for p in probabilities]

# Random IP generator
def random_ip():
    return f"{random.randint(1, 255)}.{random.randint(0, 255)}.{random.randint(0, 255)}.{random.randint(1, 254)}"

# Token generation
def generate_token_counts():
    input_tokens = random.randint(10, 100)
    output_tokens = random.randint(10, 200)
    return {
        "input_tokens": input_tokens,
        "input_tokens_details": {
            "cached_tokens": 0
        },
        "output_tokens": output_tokens,
        "output_tokens_details": {
            "reasoning_tokens": random.randint(0, 10)
        },
        "total_tokens": input_tokens + output_tokens
    }

# Output message
def generate_output_message():
    return [{
        "type": "message",
        "id": f"msg_{uuid.uuid4().hex}",
        "status": "completed",
        "role": "assistant",
        "content": [{
            "type": "output_text",
            "text": "This is a sample response generated by the assistant for demonstration purposes.",
            "annotations": []
        }]
    }]

# Main response with request metadata
def generate_response(previous_ids, request_time):
    response_time = request_time + random.randint(1, 15)  # ensure response after request

    request_id = f"req_{uuid.uuid4().hex}"
    response_id = f"resp_{uuid.uuid4().hex}"

    has_previous = random.random() < 0.1
    previous_response_id = random.choice(previous_ids) if has_previous and previous_ids else None

    model_choice = random.choice(llm_models)
    truncation_options = ["disabled", "auto", "always"]

    return {
        "id": response_id,
        "request_id": request_id,
        "object": "response",
        "created_at": response_time,
        "status": "completed",
        "error": None,
        "incomplete_details": None,
        "instructions": None,
        "max_output_tokens": None,
        "model": model_choice,
        "output": generate_output_message(),
        "parallel_tool_calls": random.choice([True, False]),
        "previous_response_id": previous_response_id,
        "reasoning": {
            "effort": None,
            "summary": None
        },
        "store": True,
        "temperature": round(random.uniform(0.0, 1.5), 2),
        "text": {
            "format": {
                "type": "text"
            }
        },
        "tool_choice": "auto",
        "tools": [],
        "top_p": 1.0,
        "truncation": random.choice(truncation_options),
        "usage": generate_token_counts(),
        "user": None,
        "metadata": {},
        "request": {
            "timestamp": request_time,
            "ip": random_ip(),
            "user_agent": random.choice(user_agents),
            "headers": {
                "X-Forwarded-For": random_ip(),
                "Content-Type": "application/json"
            }
        }
    }, response_id

def generate_responses(timestamp_val, n):
    responses = []
    response_ids = []
    for _ in range(n):
        response, resp_id = generate_response(response_ids, timestamp_val)
        responses.append(response)
        response_ids.append(resp_id)
    return responses

